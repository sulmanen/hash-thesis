@inproceedings{Alcantarilla2012,
abstract = {In this paper, we introduce KAZE features, a novelmultiscale 2D fea- ture detection and description algorithm in nonlinear scale spaces. Previous ap- proaches detect and describe features at different scale levels by building or ap- proximating the Gaussian scale space of an image. However, Gaussian blurring does not respect the natural boundaries of objects and smoothes to the same de- gree both details and noise, reducing localization accuracy and distinctiveness. In contrast, we detect and describe 2D features in a nonlinear scale space by means of nonlinear diffusion filtering. In thisway, we can make blurring locally adaptive to the image data, reducing noise but retaining object boundaries, obtaining su- perior localization accuracy and distinctiviness. The nonlinear scale space is built using efficient Additive Operator Splitting (AOS) techniques and variable con- ductance diffusion. We present an extensive evaluation on benchmark datasets and a practical matching application on deformable surfaces. Even though our features are somewhat more expensive to compute than SURF due to the con- struction of the nonlinear scale space, but comparable to SIFT, our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods.},
author = {Alcantarilla, Pablo Fern{\'{a}}ndez and Bartoli, Adrien and Davison, Andrew J.},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-33783-3_16},
isbn = {9783642337826},
issn = {03029743},
number = {PART 6},
pages = {214--227},
title = {{KAZE features}},
volume = {7577 LNCS},
year = {2012}
}
@article{Alcantarilla2013,
abstract = {We propose a novel and fast multiscale feature detection and description approach that exploits the benefits of nonlinear scale spaces. Previous attempts to detect and de- scribe features in nonlinear scale spaces are highly time consuming due to the compu- tational burden of creating the nonlinear scale space. In this paper we propose to use recent numerical schemes called Fast Explicit Diffusion (FED) embedded in a pyrami- dal framework to dramatically speed-up feature detection in nonlinear scale spaces. In addition, we introduce a Modified-Local Difference Binary (M-LDB) descriptor that is highly efficient, exploits gradient information from the nonlinear scale space, is scale and rotation invariant and has low storage requirements. We present an extensive evaluation that shows the excellent compromise between speed and performance of our approach compared to state-of-the-art methods such as BRISK, ORB, SURF, SIFT and KAZE.},
author = {Alcantarilla, Pablo and Nuevo, Jesus and Bartoli, Adrien},
doi = {10.5244/C.27.13},
isbn = {1-901725-49-9},
journal = {Procedings of the British Machine Vision Conference 2013},
pages = {13.1--13.11},
title = {{Fast Explicit Diffusion for Accelerated Features in Nonlinear Scale Spaces}},
url = {http://www.bmva.org/bmvc/2013/Papers/paper0013/index.html},
year = {2013}
}
@article{Coskun2004,
author = {Coskun, B. and Sankur, B.},
journal = {IEEE Proceedings of the Signal Processing and Communications Applications Conference},
pages = {292--295},
title = {sc},
year = {2004}
}
@article{Fawcett2006,
abstract = {Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research. ?? 2005 Elsevier B.V. All rights reserved.},
author = {Fawcett, Tom},
doi = {10.1016/j.patrec.2005.10.010},
isbn = {226},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Classifier evaluation,Evaluation metrics,ROC analysis},
number = {8},
pages = {861--874},
pmid = {9820922},
title = {{An introduction to ROC analysis}},
volume = {27},
year = {2006}
}
@inproceedings{Fridrich1999,
abstract = {We describe an algorithm for robust extraction of bits from image blocks and a method for synthesizing a Gaussian pseudo-random sequence from those bits. The bits are extracted by thresholding projections onto random smooth patterns generated from a user-specified key. The extracted bits are further utilized to synthesize a Gaussian pseudo-random sequence that changes continuously with the image block yet depends sensitively on the secret key. The proposed technique is quite general and can be combined with the majority of oblivious watermarking schemes that generate watermarks from pseudo-random sequences. We anticipate that this algorithm will find applications in many oblivious watermarking schemes including secure data embedding into videos and watermarking images for tamper detection},
author = {Fridrich, J.},
booktitle = {Proceedings IEEE International Conference on Multimedia Computing and Systems},
doi = {10.1109/MMCS.1999.778542},
isbn = {0-7695-0253-9},
keywords = {Copyright protection,Cryptography,Digital images,Fingerprint recognition,Gaussian pseudo-random sequence,Image storage,Intelligent systems,Public key,Robustness,Videos,Watermarking,copyright,image blocks,image segmentation,image sequences,image thresholding,random smooth patterns,robust bit extraction,secret key,security of data,tamper detection,user-specified key,videos,watermarking},
pages = {536--540},
title = {{Robust bit extraction from images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=778542},
volume = {2},
year = {1999}
}
@book{Gonzalez2002,
abstract = {Digital Image Processing has been the world-wide leading textbook in its field for almost 30 years. As the 1977 and 1987 editions by Gonzalez and Wintz, and the 1992 edition by Gonzalez and Woods, the present edition was prepared with students and instructors in mind. The material is timely, highly readable, and illustrated with numerous examples of practical significance. All mainstream areas of image processing are covered, including a totally revised introduction and discussion of image fundamentals, image enhancement in the spatial and frequency domains, restoration, color image processing, wavelets, image compression, morphology, segmentation, and image description. Coverage concludes with a discussion on the fundamentals of object recognition. Read more at http://ebookee.org/Digital-Image-Processing-2Ed-Gonzalez-woods{\_}59369.html{\#}x6zHhXYRriyOVDcM.99},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Gonzalez, Rc and Woods, Re},
booktitle = {Prentice Hall},
doi = {10.1016/0734-189X(90)90171-Q},
eprint = {arXiv:1011.1669v3},
isbn = {0201180758},
issn = {0024094X},
pages = {190},
pmid = {21468981},
title = {{Digital image processing}},
url = {http://mirror.klaus-uwe.me/ctan/biblio/bibtex/contrib/persian-bib/Persian-bib-userguide.pdf$\backslash$nhttp://ftp.neu6.edu.cn/mirrors/CTAN/biblio/bibtex/contrib/persian-bib/Persian-bib-userguide.pdf},
year = {2002}
}
@inproceedings{Grewenig2010,
abstract = {There are two popular ways to implement anisotropic diffusion filters with a diffusion tensor: Explicit finite difference schemes are simple but become inefficient due to severe time step size restrictions, while semi-implicit schemes are more efficient but require to solve large linear systems of equations. In our paper we present a novel class of algorithms that combine the advantages of both worlds: They are based on simple explicit schemes, while being more efficient than semi-implicit approaches. These so-called fast explicit diffusion (FED) schemes perform cycles of explicit schemes with varying time step sizes that may violate the stability restriction in up to 50 percent of all cases. FED schemes can be motivated from a decomposition of box filters in terms of explicit schemes for linear diffusion problems. Experiments demonstrate the advantages of the FED approach for time-dependent (parabolic) image enhancement problems as well as for steady state (elliptic) image compression tasks. In the latter case FED schemes are speeded up substantially by embedding them in a cascadic coarse-to-fine approach.},
author = {Grewenig, Sven and Weickert, Joachim and Bruhn, Andr{\'{e}}s},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-15986-2_54},
isbn = {3642159850},
issn = {03029743},
pages = {533--542},
title = {{From box filtering to fast explicit diffusion}},
volume = {6376 LNCS},
year = {2010}
}
@incollection{Hadmi2012,
author = {Hadmi, Azhar and Puech, William and {Ait Es Said}, Brahim and {Ait Ouahman}, Abdellah},
booktitle = {Watermarking - Volume 2},
pages = {17--42},
title = {{Perceptual Image Hashing}},
url = {http://www.intechopen.com/books/watermarking-volume-2/perceptual-image-hashing},
year = {2012}
}
@article{Hamming1950,
abstract = {Hamming, Richard W. (1950), "Error detecting and error correcting codes" (PDF), Bell System Technical Journal 29 (2): 147â€“160, doi:10.1002/j.1538-7305.1950.tb00463.x, MR 0035935.},
author = {Hamming, R. W.},
doi = {10.1002/j.1538-7305.1950.tb00463.x},
isbn = {0005-8580},
issn = {15387305},
journal = {Bell System Technical Journal},
number = {2},
pages = {147--160},
title = {{Error Detecting and Error Correcting Codes}},
volume = {29},
year = {1950}
}
@article{Jaakkola1999,
abstract = {Generative probability models such as hidden Markov models provide$\backslash$na principled way of treating missing information and dealing with$\backslash$nvariable length sequences. On the other hand, discriminative $\backslash$n$\backslash$nmethods such as support vector machines enable us to construct flexible$\backslash$ndecision boundaries and often result in classification performance$\backslash$nsuperior to that of the model based approaches. An ideal classifier$\backslash$nshould combine these two complementary approaches. In this paper,$\backslash$nwe develop a natural way of achieving this combination by deriving$\backslash$nkernel functions for use in discriminative methods such as support$\backslash$nvector machines from generative probability models. We provide a$\backslash$ntheoretical justication for this combination as well as demonstrate$\backslash$na substantial improvement in the classifcation performance in the$\backslash$ncontext of DNA and protein sequence analysis.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Jaakkola, T.S. and Haussler, D.},
doi = {10.1038/217994a0},
eprint = {arXiv:1011.1669v3},
isbn = {0262112450},
issn = {10495258},
journal = {Advances in neural information processing systems},
pages = {487--493},
pmid = {15003161},
title = {{Exploiting generative models in discriminative classifiers}},
year = {1999}
}
@inproceedings{Jegou2010,
abstract = {We address the problem of image search on a very large scale, where three constraints have to be considered jointly: the accuracy of the search, its efficiency, and the memory usage of the representation. We first propose a simple yet efficient way of aggregating local image descriptors into a vector of limited dimension, which can be viewed as a simplification of the Fisher kernel representation. We then show how to jointly optimize the dimension reduction and the indexing algorithm, so that it best preserves the quality of vector comparison. The evaluation shows that our approach significantly outperforms the state of the art: the search accuracy is comparable to the bag-of-features approach for an image representation that fits in 20 bytes. Searching a 10 million image dataset takes about 50ms.},
author = {J{\'{e}}gou, Herv{\'{e}} and Douze, Matthijs and Schmid, Cordelia and P{\'{e}}rez, Patrick},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2010.5540039},
isbn = {9781424469840},
issn = {10636919},
pages = {3304--3311},
pmid = {22156101},
title = {{Aggregating local descriptors into a compact image representation}},
year = {2010}
}
@incollection{mihccak2001new,
author = {KÄ±van, M},
booktitle = {Security and privacy in digital rights management},
pages = {13--21},
publisher = {Springer},
title = {{New Iterative Geometric Methods for Robust Perceptual Image Hashing}},
year = {2002}
}
@article{Lowe2004,
abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
archivePrefix = {arXiv},
arxivId = {cs/0112017},
author = {Lowe, David G.},
doi = {10.1023/B:VISI.0000029664.99615.94},
eprint = {0112017},
isbn = {1568811012},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {Image matching,Invariant features,Object recognition,Scale invariance},
number = {2},
pages = {91--110},
pmid = {20064111},
primaryClass = {cs},
title = {{Distinctive image features from scale-invariant keypoints}},
volume = {60},
year = {2004}
}
@inproceedings{Lowe1999,
abstract = {An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds},
archivePrefix = {arXiv},
arxivId = {cs/0112017},
author = {Lowe, David G.},
booktitle = {Proceedings of the Seventh IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.1999.790410},
eprint = {0112017},
isbn = {0-7695-0164-8},
issn = {0-7695-0164-8},
number = {[8},
pages = {1150--1157},
pmid = {15806121},
primaryClass = {cs},
title = {{Object recognition from local scale-invariant features}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=790410},
volume = {2},
year = {1999}
}
@article{Perona1990,
abstract = {A new definition of scale-space is suggested, and a class of algorithms used to realize a diffusion process is introduced. The diffusion coefficient is chosen to vary spatially in such a way as to encourage intraregion smoothing rather than interregion smoothing. It is shown that the `no new maxima should be generated at coarse scales' property of conventional scale space is preserved. As the region boundaries in the approach remain sharp, a high-quality edge detector which successfully exploits global information is obtained. Experimental results are shown on a number of images. Parallel hardware implementations are made feasible because the algorithm involves elementary, local operations replicated over the image},
author = {Perona, P and Malik, J},
doi = {10.1109/34.56205},
isbn = {0162-8828},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Anisotropic magnetoresistance,Detectors,Diffusion processes,Equations,Filtering,Hardware,Image edge detection,Image generation,Image resolution,Kernel,Smoothing methods,anisotropic diffusion,edge detection,filtering and prediction theory,intraregion smoothing,parallel processing,pattern recognition,picture processing,scale-space},
number = {7},
pages = {629--639},
pmid = {19268610},
title = {{Scale-space and edge detection using anisotropic diffusion}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=56205},
volume = {12},
year = {1990}
}
@inproceedings{Perronnin2007,
abstract = {Within the field of pattern classification, the Fisher kernel is a powerful framework which combines the strengths of generative and discriminative approaches. The idea is to characterize a signal with a gradient vector derived from a generative probability model and to subsequently feed this representation to a discriminative classifier. We propose to apply this framework to image categorization where the input signals are images and where the underlying generative model is a visual vocabulary: a Gaussian mixture model which approximates the distribution of low-level features in images. We show that Fisher kernels can actually be understood as an extension of the popular bag-of-visterms. Our approach demonstrates excellent performance on two challenging databases: an in-house database of 19 object/scene categories and the recently released VOC 2006 database. It is also very practical: it has low computational needs both at training and test time and vocabularies trained on one set of categories can be applied to another set without any significant loss in performance.},
author = {Perronnin, Florent and Dance, Christopher},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2007.383266},
isbn = {1424411807},
issn = {10636919},
title = {{Fisher kernels on visual vocabularies for image categorization}},
year = {2007}
}
@misc{PhilbinJamesArandjelovicReljaZisserman2012,
author = {{Philbin, James Arandjelovi{\'{c}}, Relja Zisserman}, Andrew},
title = {{The Oxford Buildings Dataset}},
url = {http://www.robots.ox.ac.uk/{~}vgg/data/oxbuildings/},
year = {2012}
}
@article{Sivic2003,
abstract = {We describe an approach to object and scene retrieval which searches for and localizes all the occurrences of a user outlined object in a video. The object is represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination and partial occlusion. The temporal continuity of the video within a shot is used to track the regions in order to reject unstable regions and reduce the effects of noise in the descriptors. The analogy with text retrieval is in the implementation where matches on descriptors are pre-computed (using vector quantization), and inverted file systems and document rankings are used. The result is that retrieved is immediate, returning a ranked list of key frames/shots in the manner of Google. The method is illustrated for matching in two full length feature films.},
archivePrefix = {arXiv},
arxivId = {1504.06897},
author = {Sivic, J. and Zisserman, A.},
doi = {10.1109/ICCV.2003.1238663},
eprint = {1504.06897},
isbn = {0-7695-1950-4},
issn = {00189219},
journal = {IEEE International Conference on Computer Vision},
pages = {1470--1477},
title = {{Video Google: a text retrieval approach to object matching in videos}},
url = {http://ieeexplore.ieee.org/xpl/login.jsp?tp={\&}arnumber=1238663},
year = {2003}
}
@misc{Vedaldi2012,
author = {Vedaldi, Andrea and Zisserman, Andrew},
title = {{Recognition of object instaces practical}},
url = {http://www.robots.ox.ac.uk/{~}vgg/practicals/instance-recognition/index.html},
urldate = {2016-04-30},
year = {2012}
}
@article{Weickert1998,
abstract = {Nonlinear diffusion filtering in image processing is usually performed with explicit schemes. They are only stable for very small time steps, which leads to poor efficiency and limits their practical use. Based on a discrete nonlinear diffusion scale-space framework we present semi-implicit schemes which are stable for all time steps. These novel schemes use an additive operator splitting (AOS), which guarantees equal treatment of all coordinate axes. They can be implemented easily in arbitrary dimensions, have good rotational invariance and reveal a computational complexity and memory requirement which is linear in the number of pixels. Examples demonstrate that, under typical accuracy requirements, AOS schemes are at least ten times more efficient than the widely used explicit schemes.},
author = {Weickert, Joachim and {Ter Haar Romeny}, Bart M. and Viergever, Max A.},
doi = {10.1109/83.661190},
isbn = {1057-7149 VO - 7},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Absolute stability,Nonlinear diffusion,Recursive filters},
number = {3},
pages = {398--410},
pmid = {18276260},
title = {{Efficient and reliable schemes for nonlinear diffusion filtering}},
volume = {7},
year = {1998}
}
@inproceedings{Yang2006,
abstract = {Image perceptual hashing has been proposed to identify or authenticate image contents in a robust way against distortions caused by compression, noise, common signal processing and geometrical modifications, while still holding a good discriminability for different ones in sense of human perception. We propose and compare four normalized block mean value based image perceptual hashing algorithms which demonstrate higher performances than other existing algorithms in robustness-anddiscriminalibility and simplicity for implementation. Overlapped blocking and rotation operations are employed to enhance the robustness to geometrical distortions. To evaluate the proposed algorithms{\^{A}}Â¿ robustness and discriminability, given fixed modifications, identification ratio is used; and given fixed content classification, receiver operating curves is obtained.},
author = {Yang, Bian and Gu, Fan and Niu, Xiamu},
booktitle = {Proceedings - 2006 International Conference on Intelligent Information Hiding and Multimedia Signal Processing, IIH-MSP 2006},
doi = {10.1109/IIH-MSP.2006.265125},
isbn = {0769527450},
pages = {167--170},
title = {{Block mean value based image perceptual hashing}},
year = {2006}
}
@article{Zauner2010,
abstract = {Perceptual image hash functions produce hash values based on the image's visual appearance. A perceptual hash can also be referred to as e.g. a robust hash or a ngerprint. Such a function calculates similar hash values for similar images, whereas for dissimilar images dissimilar hash values are calculated. Finally, using an adequate distance or similarity function to compare two perceptual hash values, it can be decided whether two images are perceptually di erent or not. Perceptual image hash functions can be used e.g. for the identi cation or integrity veri cation of images. This thesis proposes a novel benchmarking framework, called Rihamark, for perceptual image hash functions. Subsequently, four di erent percep- tual image hash functions were benchmarked: A discrete Cosine transform (DCT) based , a Marr-Hildreth operator based, a radial variance based and a block mean value based image hash function. pHash, an open source im- plementation of various perceptual hash functions, was used to benchmark the rst three functions. The latter, the block mean value based image hash function was implemented by the author of this thesis himself. The block mean value based image hash function outperforms the other hash functions in terms of speed. The DCT based image hash function is the slowest. Although the Marr-Hildreth operator based image hash function is not the fastest nor the most robust, it o ers by far the best discriminiative abilities. Interestingly enough, the performance in terms of discriminiative ability does not depend on the content of the images. That is, no matter whether the visual appearance of the images compared was very similar or not, the performance of the particular hash function did not change sig- ni cantly. Di erent image operations, like horizontal ipping, rotating or resizing, were used to test the robustness of the image hash functions. An interesting result is that none of the tested image hash function is robust against ipping an image horizontally.},
author = {Zauner, Christoph},
journal = {Master's thesis, Upper Austria University of Applied {\ldots}},
pages = {107},
title = {{Implementation and benchmarking of perceptual image hash functions}},
url = {w},
year = {2010}
}
@misc{,
booktitle = {W3C Architecture Domain},
title = {{Naming and Addressing: URIs, URLs, ...}},
url = {https://www.w3.org/Addressing/},
urldate = {2016-04-12}
}
@misc{,
booktitle = {W3C Wiki},
title = {{Definition of User Agent}},
url = {https://www.w3.org/WAI/UA/work/wiki/Definition{\_}of{\_}User{\_}Agent},
urldate = {2016-04-12}
}
