@article{Fawcett2006,
abstract = {Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research. ?? 2005 Elsevier B.V. All rights reserved.},
author = {Fawcett, Tom},
doi = {10.1016/j.patrec.2005.10.010},
isbn = {226},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Classifier evaluation,Evaluation metrics,ROC analysis},
number = {8},
pages = {861--874},
pmid = {9820922},
title = {{An introduction to ROC analysis}},
volume = {27},
year = {2006}
}
@incollection{Hadmi2012,
author = {Hadmi, Azhar and Puech, William and {Ait Es Said}, Brahim and {Ait Ouahman}, Abdellah},
booktitle = {Watermarking - Volume 2},
pages = {17--42},
title = {{Perceptual Image Hashing}},
url = {http://www.intechopen.com/books/watermarking-volume-2/perceptual-image-hashing},
year = {2012}
}
@inproceedings{Jegou2010,
abstract = {We address the problem of image search on a very large scale, where three constraints have to be considered jointly: the accuracy of the search, its efficiency, and the memory usage of the representation. We first propose a simple yet efficient way of aggregating local image descriptors into a vector of limited dimension, which can be viewed as a simplification of the Fisher kernel representation. We then show how to jointly optimize the dimension reduction and the indexing algorithm, so that it best preserves the quality of vector comparison. The evaluation shows that our approach significantly outperforms the state of the art: the search accuracy is comparable to the bag-of-features approach for an image representation that fits in 20 bytes. Searching a 10 million image dataset takes about 50ms.},
author = {J{\'{e}}gou, Herv{\'{e}} and Douze, Matthijs and Schmid, Cordelia and P{\'{e}}rez, Patrick},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2010.5540039},
isbn = {9781424469840},
issn = {10636919},
pages = {3304--3311},
pmid = {22156101},
title = {{Aggregating local descriptors into a compact image representation}},
year = {2010}
}
@article{Lowe2004,
abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
archivePrefix = {arXiv},
arxivId = {cs/0112017},
author = {Lowe, David G.},
doi = {10.1023/B:VISI.0000029664.99615.94},
eprint = {0112017},
isbn = {1568811012},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {Image matching,Invariant features,Object recognition,Scale invariance},
number = {2},
pages = {91--110},
pmid = {20064111},
primaryClass = {cs},
title = {{Distinctive image features from scale-invariant keypoints}},
volume = {60},
year = {2004}
}
@inproceedings{Lowe1999,
abstract = {An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds},
archivePrefix = {arXiv},
arxivId = {cs/0112017},
author = {Lowe, David G.},
booktitle = {Proceedings of the Seventh IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.1999.790410},
eprint = {0112017},
isbn = {0-7695-0164-8},
issn = {0-7695-0164-8},
number = {[8},
pages = {1150--1157},
pmid = {15806121},
primaryClass = {cs},
title = {{Object recognition from local scale-invariant features}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=790410},
volume = {2},
year = {1999}
}
@misc{PhilbinJamesArandjelovicReljaZisserman2012,
author = {{Philbin, James Arandjelovi{\'{c}}, Relja Zisserman}, Andrew},
title = {{The Oxford Buildings Dataset}},
url = {http://www.robots.ox.ac.uk/{~}vgg/data/oxbuildings/},
year = {2012}
}
@misc{Vedaldi2012,
author = {Vedaldi, Andrea and Zisserman, Andrew},
title = {{Recognition of object instaces practical}},
url = {http://www.robots.ox.ac.uk/{~}vgg/practicals/instance-recognition/index.html},
urldate = {2016-04-30},
year = {2012}
}
@inproceedings{Yang2006,
abstract = {Image perceptual hashing has been proposed to identify or authenticate image contents in a robust way against distortions caused by compression, noise, common signal processing and geometrical modifications, while still holding a good discriminability for different ones in sense of human perception. We propose and compare four normalized block mean value based image perceptual hashing algorithms which demonstrate higher performances than other existing algorithms in robustness-anddiscriminalibility and simplicity for implementation. Overlapped blocking and rotation operations are employed to enhance the robustness to geometrical distortions. To evaluate the proposed algorithms{\^{A}}Â¿ robustness and discriminability, given fixed modifications, identification ratio is used; and given fixed content classification, receiver operating curves is obtained.},
author = {Yang, Bian and Gu, Fan and Niu, Xiamu},
booktitle = {Proceedings - 2006 International Conference on Intelligent Information Hiding and Multimedia Signal Processing, IIH-MSP 2006},
doi = {10.1109/IIH-MSP.2006.265125},
isbn = {0769527450},
pages = {167--170},
title = {{Block mean value based image perceptual hashing}},
year = {2006}
}
@article{Zauner2010,
abstract = {Perceptual image hash functions produce hash values based on the image's visual appearance. A perceptual hash can also be referred to as e.g. a robust hash or a ngerprint. Such a function calculates similar hash values for similar images, whereas for dissimilar images dissimilar hash values are calculated. Finally, using an adequate distance or similarity function to compare two perceptual hash values, it can be decided whether two images are perceptually di erent or not. Perceptual image hash functions can be used e.g. for the identi cation or integrity veri cation of images. This thesis proposes a novel benchmarking framework, called Rihamark, for perceptual image hash functions. Subsequently, four di erent percep- tual image hash functions were benchmarked: A discrete Cosine transform (DCT) based , a Marr-Hildreth operator based, a radial variance based and a block mean value based image hash function. pHash, an open source im- plementation of various perceptual hash functions, was used to benchmark the rst three functions. The latter, the block mean value based image hash function was implemented by the author of this thesis himself. The block mean value based image hash function outperforms the other hash functions in terms of speed. The DCT based image hash function is the slowest. Although the Marr-Hildreth operator based image hash function is not the fastest nor the most robust, it o ers by far the best discriminiative abilities. Interestingly enough, the performance in terms of discriminiative ability does not depend on the content of the images. That is, no matter whether the visual appearance of the images compared was very similar or not, the performance of the particular hash function did not change sig- ni cantly. Di erent image operations, like horizontal ipping, rotating or resizing, were used to test the robustness of the image hash functions. An interesting result is that none of the tested image hash function is robust against ipping an image horizontally.},
author = {Zauner, Christoph},
journal = {Master's thesis, Upper Austria University of Applied {\ldots}},
pages = {107},
title = {{Implementation and benchmarking of perceptual image hash functions}},
url = {w},
year = {2010}
}
@misc{,
booktitle = {W3C Architecture Domain},
title = {{Naming and Addressing: URIs, URLs, ...}},
url = {https://www.w3.org/Addressing/},
urldate = {2016-04-12}
}
@misc{,
booktitle = {W3C Wiki},
title = {{Definition of User Agent}},
url = {https://www.w3.org/WAI/UA/work/wiki/Definition{\_}of{\_}User{\_}Agent},
urldate = {2016-04-12}
}
@article{Coskun2004,
author = {Coskun, B. and Sankur, B.},
journal = {IEEE Proceedings of the Signal Processing and Communications Applications Conference},
pages = {292--295},
title = {{Robust video hash extraction}},
year = {2004}
}
